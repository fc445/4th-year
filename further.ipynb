{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features import *\n",
    "import librosa\n",
    "import librosa.display as display\n",
    "import scipy\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from model_02_functions import *\n",
    "import sklearn\n",
    "from train_period_checker import max_pooling\n",
    "import matplotlib.colors as colors\n",
    "from timetables import trains_in_period\n",
    "from wavfile_manipulations import extract_wavfile_and_date\n",
    "from octave_band import *\n",
    "from initial_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [1414,13000,80000,140000,380000,800000,1200000]\n",
    "acc = [0.8,0.84,0.845,0.855,0.87,0.871,0.871]\n",
    "fig = plt.figure(figsize=(8,4.5))\n",
    "plt.plot(params, acc, color='#e32017')\n",
    "plt.xlim\n",
    "plt.xscale('log')\n",
    "plt.xlabel('No. Parameters')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.savefig('final_figures/further/simplecomplex',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from scipy.fftpack import fft\n",
    "from scipy.fftpack import ifft\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.colors as colors\n",
    "import scipy\n",
    "from scipy.signal import welch\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import Input, Model, layers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, ReLU, AveragePooling2D, Add\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "from model_02_functions import find_train_trainbar_array_datetime, rolling_spectrograms_with_labels_02\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('network5_model.h5')\n",
    "model.load_weights('network5_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore('initial_datasets/testing_hour13.h5')\n",
    "#store.close()\n",
    "test = store['first']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore('initial_datasets/spectro3.h5')\n",
    "#store.close()\n",
    "data = store['first']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [1 if i==0 else 0 for i in data.no_train]\n",
    "#data['no_train'] = no_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([data[data.no_train==0],data[data.no_train==1].sample(300)],ignore_index=True).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(final.array.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(final.drop(['array'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in y.argmax(axis=1):\n",
    "    if i==4:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X[0:500])\n",
    "pred=np.transpose(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_singles(array):\n",
    "    output = []\n",
    "    for i in array:\n",
    "        if i==1:\n",
    "            for j in range(5):\n",
    "                output.append(1)\n",
    "        else:\n",
    "            for j in range(5):\n",
    "                output.append(0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data13, time = extract_wavfile_and_date('train_recordings/hour1301.wav', samplerate=3200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = trains_in_period(['cen_eas','cen_wes','bak_nor','bak_sou','vic_nor','vic_sou'],time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.5))\n",
    "train_audio = moving_average(abs(return_octave_filtered(data13,samplerate=3200,octave_band=125)),1500)\n",
    "t = np.linspace(0,3600,len(train_audio))\n",
    "plt.xlabel('Time ($s$)')\n",
    "plt.ylabel('Amplitude ($V$)')\n",
    "plt.xlim([0,600])\n",
    "plt.ylim([0,0.0015])\n",
    "plt.plot(t,train_audio,color='#0098D4',lw=0.3)\n",
    "\"\"\"for i in times:\n",
    "    for j in times[i]:\n",
    "        plt.axvline(j,color='#E32017',lw=2.5,alpha=1)\n",
    "plt.axvline(times['cen_eas'][0],color='#E32017',lw=2.5,alpha=1,label='Expected Train')\"\"\"\n",
    "plt.plot(np.linspace(0,3600,718),[0.001*i for i in pred], color='#E32017')\n",
    "#plt.legend(loc='upper right')\n",
    "plt.savefig('final_figures/approach/CNN',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = metrics.confusion_matrix(y[500:1000].argmax(axis=1),pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = [[586,250],[222,389]]\n",
    "fig = plt.figure(figsize=(8,4.5))\n",
    "x_label = ['Positive','Negative']\n",
    "sns.heatmap(cf_matrix, annot=True,cmap='Blues',xticklabels=x_label,yticklabels=x_label,cbar=False,fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('final_figures/intro/confusion',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_metrics(c):\n",
    "    acc = (c[0]+c[1])/(sum(c))\n",
    "    pre = c[0]/(c[0]+c[2])\n",
    "    rec = c[0]/(c[0]+c[3])\n",
    "    f1 = 2*pre*rec/(pre+rec)\n",
    "    return [acc,pre,rec,f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(find_metrics([187,120,58,353]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('networkreallysimple_model.h5')\n",
    "model.load_weights('networkreallysimple_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X[0:500])\n",
    "pred=np.transpose(pred)\n",
    "pred=pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = metrics.confusion_matrix(y[0:500].argmax(axis=1),pred.argmax(axis=1))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.5))\n",
    "x_label = ['cen_eas','cen_wes','bak_sou','bak_nor','vic_sou','vic_nor','no train']\n",
    "sns.heatmap(matrix, annot=True,cmap='Blues',xticklabels=x_label,yticklabels=x_label,cbar=False,fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('final_figures/further/simpleconfusion',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('networkcomplex_model.h5')\n",
    "model.load_weights('network7complexweights.h5')\n",
    "pred = model.predict(X[0:500])\n",
    "pred=np.transpose(pred)\n",
    "pred=pred[0]\n",
    "matrix = metrics.confusion_matrix(y[:500].argmax(axis=1),pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.5))\n",
    "x_label = ['cen_eas','cen_wes','bak_sou','bak_nor','vic_sou','vic_nor','no train']\n",
    "sns.heatmap(matrix, annot=True,cmap='Blues',xticklabels=x_label,yticklabels=x_label,cbar=False,fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('final_figures/further/complexconfusion',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('network7_model.h5')\n",
    "model.load_weights('network7_weights.h5')\n",
    "pred = model.predict(X[0:500])\n",
    "pred=np.transpose(pred)\n",
    "pred=pred[0]\n",
    "matrix = metrics.confusion_matrix(y[:500].argmax(axis=1),pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.5))\n",
    "x_label = ['cen_eas','cen_wes','bak_sou','bak_nor','vic_sou','vic_nor','no train']\n",
    "sns.heatmap(matrix, annot=True,cmap='Blues',xticklabels=x_label,yticklabels=x_label,cbar=False,fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('final_figures/further/confusion7',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('networkfinal_model.h5')\n",
    "model.load_weights('networkfinal_weights.h5')\n",
    "pred = model.predict(X[0:500])\n",
    "pred=np.transpose(pred)\n",
    "pred=pred[0]\n",
    "matrix = metrics.confusion_matrix(y[:500].argmax(axis=1),pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.5))\n",
    "x_label = ['cen_eas','cen_wes','bak_sou','bak_nor','vic_sou','vic_nor','no train']\n",
    "sns.heatmap(matrix, annot=True,cmap='Blues',xticklabels=x_label,yticklabels=x_label,cbar=False,fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('final_figures/further/confusionfinal',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_metrics(c):\n",
    "    acc = (c[0]+c[1])/(sum(c))\n",
    "    pre = c[0]/(c[0]+c[2])\n",
    "    rec = c[0]/(c[0]+c[3])\n",
    "    f1 = 2*pre*rec/(pre+rec)\n",
    "    return [acc,pre,rec,f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = [405,42,5,16]\n",
    "print(find_metrics(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = [415,40,15,12]\n",
    "print(find_metrics(conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbd = pd.read_csv('sbd126.csv')\n",
    "sbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbd = pd.read_csv('SBD/sbd240.csv')\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd241.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd242.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd243.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd244.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd245.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd246.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd247.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd248.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd249.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd250.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd251.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd252.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd253.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd254.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd255.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd256.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd257.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd258.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd259.csv')],axis=0)\n",
    "sbd = pd.concat([sbd,pd.read_csv('SBD/sbd260.csv')],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4888576/2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sbd['Column4'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.5))\n",
    "train_audio = moving_average(abs(return_octave_filtered(sbd['Column4'],samplerate=2048,octave_band=125)),1500)\n",
    "t = np.linspace(0,2387,len(train_audio))\n",
    "plt.xlabel('Time ($s$)')\n",
    "plt.ylabel('Amplitude ($V$)')\n",
    "#plt.xlim([0,600])\n",
    "#plt.ylim([0,0.0015])\n",
    "plt.plot(t,train_audio,color='#0098D4',lw=0.3)\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "#plt.savefig('final_figures/further/predictfinal',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_spectrograms_no_labels(data, leng, samplerate=1000, interval=10, lag=5):\n",
    "    #empty array for spectrograms and whether a train\n",
    "    output = []\n",
    "    train = []\n",
    "\n",
    "    #find start times for spectrograms\n",
    "    starts = range(0,samplerate*(leng-interval),samplerate*lag)\n",
    " \n",
    "    for start in tqdm(starts):\n",
    "        end = start + interval*samplerate    \n",
    "        f0, t0, feature = scipy.signal.spectrogram(data[start:end], fs=samplerate, window='hamming', nperseg=39, noverlap=0, nfft=640)\n",
    "        feature = max_pooling(feature, pool_size=(3,3), pool_overlap=(1,1))\n",
    "        lim = [(50*len(feature))//(samplerate/2), (300*len(feature))//(samplerate/2)]\n",
    "        feature = feature[int(lim[0]):int(lim[1])]\n",
    "        feature = [i[:125] for i in feature]\n",
    "        #feature = [i[:128] for i in librosa.feature.melspectrogram(y=data[start:end], sr=samplerate,n_fft=100,hop_length=78)]\n",
    "        #feature = librosa.feature.mfcc(y=data[start:end],sr=samplerate,n_mfcc=100, n_mels=100, hop_length=101, fmin=0, fmax=None, htk=False)\n",
    "        output.append(feature)\n",
    "\n",
    "    #join spectrograms to labels\n",
    "    output = pd.Series(normalise(output), name='array')\n",
    "\n",
    "    print(output.shape)\n",
    "    print(len(output.array[0]))\n",
    "    print(len(output.array[0][0]))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = rolling_spectrograms_no_labels(sbd['Column4'][:4884480],leng=1385,samplerate=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=new.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('networkfinal_model.h5')\n",
    "model.load_weights('networkfinal_weights.h5')\n",
    "pred = model.predict(new)\n",
    "pred=np.transpose(pred)\n",
    "pred=pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.5))\n",
    "train_audio = moving_average(abs(return_octave_filtered(sbd['Column4'],samplerate=2048,octave_band=125)),1500)\n",
    "t = np.linspace(0,2387,len(train_audio))\n",
    "a = 2387/275\n",
    "plt.xlabel('Time ($s$)')\n",
    "plt.ylabel('Amplitude ($V$)')\n",
    "plt.xlim([1500,2387])\n",
    "#plt.xticks([0,200,400,600,800,1000])\n",
    "plt.ylim([0,0.0002])\n",
    "plt.plot(t,train_audio,color='#0098D4',lw=0.3)\n",
    "\n",
    "for i,j in enumerate(pred.argmax(axis=1)):\n",
    "    if j!=6:\n",
    "        plt.fill_between(np.linspace(i*a,a*(i+1),2),[0.00025]*2, color='#e32017',alpha=0.4)\n",
    "plt.fill_between(np.linspace(0,2,2),[0.00025]*2, color='#e32017',alpha=0.4,label='Predicted Train')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('final_figures/further/sbdpredict',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_output_with_labels_02(hours, leng, samplerate=2048, interval=10, lag=5, ste_octave=None):\n",
    "    #empty array for spectrograms and whether a train\n",
    "    zcr = []\n",
    "    ste = []\n",
    "    rms = []\n",
    "    peak = []\n",
    "    cent = []\n",
    "    rolloff = []\n",
    "\n",
    "    #find start times for spectrograms\n",
    "    starts = range(0,samplerate*(leng-interval),samplerate*lag)\n",
    "\n",
    "    #loop through trains_array\n",
    "    #feature = librosa.feature.mfcc(y=data[start:end], sr=samplerate, n_mfcc=40, n_mels=40, hop_length=160, fmin=0, fmax=None, htk=False)\n",
    "    for start in tqdm(starts):\n",
    "        end = start + interval*samplerate    \n",
    "        zcr.append(zero_crossing_rate(data[start:end], samplerate=samplerate, frame_length=samplerate*interval)[0])\n",
    "        ste.append(short_time_energy(data[start:end], samplerate=samplerate, frame_length=samplerate*interval)[0])\n",
    "        rms.append(RMS(data[start:end], frame_length=samplerate*interval)[0])\n",
    "        peak.append(peak_value(data[start:end], samplerate=samplerate, frame_length=samplerate*interval)[0])\n",
    "        cent.append(spectral_centroid(data[start:end], samplerate=samplerate, frame_length=samplerate*interval)[0])\n",
    "        rolloff.append(spectral_roll_off(data[start:end], samplerate=samplerate, frame_length=samplerate*interval)[0])\n",
    "\n",
    "    #join spectrograms to labels\n",
    "\n",
    "    output = pd.Series(normalisei(zcr), name='zcr')\n",
    "    output = pd.concat([output, pd.Series(normalisei(ste), name='ste')],axis=1)\n",
    "    output = pd.concat([output, pd.Series(normalisei(rms), name='rms')],axis=1)\n",
    "    output = pd.concat([output, pd.Series(normalisei(peak), name='peak')],axis=1)\n",
    "    output = pd.concat([output, pd.Series(normalisei(cent), name='cent')],axis=1)\n",
    "    output = pd.concat([output, pd.Series(normalisei(rolloff), name='rolloff')],axis=1)\n",
    "\n",
    "    print(output.shape)\n",
    "\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
