{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features import *\n",
    "import librosa\n",
    "import librosa.display as display\n",
    "import scipy\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from model_02_functions import *\n",
    "import sklearn\n",
    "from train_period_checker import max_pooling\n",
    "import matplotlib.colors as colors\n",
    "from timetables import trains_in_period\n",
    "from wavfile_manipulations import extract_wavfile_and_date\n",
    "from octave_band import *\n",
    "from initial_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_singles(array):\n",
    "    output = []\n",
    "    for i in array:\n",
    "        if i==1:\n",
    "            for j in range(5):\n",
    "                output.append(1)\n",
    "        else:\n",
    "            for j in range(5):\n",
    "                output.append(0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore('initial_datasets/final1.h5')\n",
    "data = store['first']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for i in range(len(data['cent'])):\n",
    "    summ = sum([data['cen_eas'][i],data['cen_wes'][i],data['bak_sou'][i],data['bak_nor'][i],data['vic_sou'][i],data['vic_nor'][i]])\n",
    "    if summ == 0:\n",
    "        train.append(0)\n",
    "    else:\n",
    "        train.append(1)\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train'] = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([data[data.train==1].sample(1477),data[data.train==0].sample(1477)],ignore_index=True).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(final.drop(['cen_eas','cen_wes','bak_sou','bak_nor','vic_sou','vic_nor','train'],axis=1))\n",
    "Y = np.array(final.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(data.drop(['cen_eas','cen_wes','bak_sou','bak_nor','vic_sou','vic_nor','train'],axis=1))\n",
    "Y_test = np.array(data.train)\n",
    "print(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = make_pipeline(StandardScaler(),SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "clf3.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_svm3 = clf3.predict(X_test[8616:9334])\n",
    "print(len(labels_svm3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data13, time = extract_wavfile_and_date('train_recordings/hour1301.wav', samplerate=3200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.5))\n",
    "train_audio = moving_average(abs(return_octave_filtered(data13,samplerate=3200,octave_band=125)),1500)\n",
    "t = np.linspace(0,3600,len(train_audio))\n",
    "plt.xlabel('Time ($s$)')\n",
    "plt.ylabel('Amplitude ($V$)')\n",
    "plt.xlim([0,600])\n",
    "plt.ylim([0,0.0015])\n",
    "plt.plot(t,train_audio,color='#0098D4',lw=0.3)\n",
    "\"\"\"for i in times:\n",
    "    for j in times[i]:\n",
    "        plt.axvline(j,color='#E32017',lw=2.5,alpha=1)\n",
    "plt.axvline(times['cen_eas'][0],color='#E32017',lw=2.5,alpha=1,label='Expected Train')\"\"\"\n",
    "plt.fill_between(np.linspace(0,3600,3590),[0.0015*i for i in expand_singles(labels_svm3)], color='#E32017',alpha=0.4)\n",
    "plt.fill_between([1000,2000],[0,0],color='#E32017',alpha=0.4, label='Predicted Train')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('final_figures/initial/glm_predict',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principle_components = pd.DataFrame(pca.fit_transform(X_test),columns=['pc1','pc2','pc3'])\n",
    "principle_components['train'] = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(principle_components)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.5))\n",
    "labels_svm3 = clf3.predict(X_test[8616:9334])\n",
    "train_audio = np.array(moving_average(principle_components.pc1[8616:9334],10))\n",
    "t = np.linspace(0,3600,len(train_audio))\n",
    "plt.xlabel('Time ($s$)')\n",
    "plt.ylabel('Principle Component 1')\n",
    "plt.xlim([0,600])\n",
    "plt.ylim([0,4])\n",
    "plt.plot(t,[i for i in train_audio],color='#0098D4',lw=1.5)\n",
    "\"\"\"for i in times:\n",
    "    for j in times[i]:\n",
    "        plt.axvline(j,color='#E32017',lw=2.5,alpha=1)\n",
    "plt.axvline(times['cen_eas'][0],color='#E32017',lw=2.5,alpha=1,label='Expected Train')\"\"\"\n",
    "plt.fill_between(np.linspace(0,3600,3590),[(6*i) for i in expand_singles(labels_svm3)], color='#E32017',alpha=0.4)\n",
    "plt.fill_between([1000,2000],[0,0],color='#E32017',alpha=0.4, label='Predicted Train')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('final_figures/initial/glmpc1',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_svm3 = clf3.predict(X_test[718:1436])\n",
    "data1, time = extract_wavfile_and_date('train_recordings/hour0101.wav', samplerate=3200)\n",
    "fig = plt.figure(figsize=(8,4.5))\n",
    "train_audio = moving_average(abs(return_octave_filtered(data1,samplerate=3200,octave_band=125)),1500)\n",
    "t = np.linspace(0,3600,len(train_audio))\n",
    "plt.xlabel('Time ($s$)')\n",
    "plt.ylabel('Amplitude ($V$)')\n",
    "plt.xlim([0,600])\n",
    "plt.ylim([0,0.0015])\n",
    "plt.plot(t,train_audio,color='#0098D4',lw=0.3)\n",
    "\"\"\"for i in times:\n",
    "    for j in times[i]:\n",
    "        plt.axvline(j,color='#E32017',lw=2.5,alpha=1)\n",
    "plt.axvline(times['cen_eas'][0],color='#E32017',lw=2.5,alpha=1,label='Expected Train')\"\"\"\n",
    "plt.fill_between(np.linspace(0,3600,3590),[0.0015*i for i in expand_singles(labels_svm3)], color='#E32017',alpha=0.4)\n",
    "plt.fill_between([1000,2000],[0,0],color='#E32017',alpha=0.4, label='Predicted Train')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('final_figures/initial/glm_predict2',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(expand_singles(labels_svm3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.5))\n",
    "train_audio = np.array(moving_average(principle_components.pc1[718:1436],10))\n",
    "t = np.linspace(0,3600,len(train_audio))\n",
    "plt.xlabel('Time ($s$)')\n",
    "plt.ylabel('Principle Component 1')\n",
    "plt.xlim([0,600])\n",
    "plt.ylim([0,4])\n",
    "plt.plot(t,[i for i in train_audio],color='#0098D4',lw=1.5)\n",
    "\"\"\"for i in times:\n",
    "    for j in times[i]:\n",
    "        plt.axvline(j,color='#E32017',lw=2.5,alpha=1)\n",
    "plt.axvline(times['cen_eas'][0],color='#E32017',lw=2.5,alpha=1,label='Expected Train')\"\"\"\n",
    "plt.fill_between(np.linspace(0,3600,3590),[6*i for i in expand_singles(labels_svm3)], color='#E32017',alpha=0.4)\n",
    "plt.fill_between([1000,2000],[0,0],color='#E32017',alpha=0.4, label='Predicted Train')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('final_figures/initial/glmpc12',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisei(arr):\n",
    "    \"\"\"\n",
    "    scales array to between 0 and 1\n",
    "    \"\"\"\n",
    "    mean = np.mean(np.array(arr).flatten())\n",
    "    square_mean = np.mean([i**2 for i in np.array(arr).flatten()])\n",
    "    var = square_mean - mean**2\n",
    "\n",
    "    for i in range(len(arr)):\n",
    "        arr[i] = (arr[i]-mean)/(np.sqrt(var))\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "for column in data.drop(['cen_eas','cen_wes','bak_sou','bak_nor','vic_sou','vic_nor','train'],axis=1):\n",
    "    neww = []\n",
    "    arr = np.array(data[column])\n",
    "    for i in np.linspace(0,10052-718,28):\n",
    "        nor = normalisei(arr[int(i):int(i+359)])\n",
    "        neww.append(nor)\n",
    "    new.append(neww)\n",
    "old = new\n",
    "for i,j in enumerate(new):\n",
    "    new[i] = np.concatenate(j)\n",
    "new = np.transpose(new)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.DataFrame(new, columns=['zcr','ste','rms','peak','cent','rolloff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['train'] = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([data[data.train==1].sample(1477),data[data.train==0].sample(1477)],ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "X = np.array(final.drop(['cen_eas','cen_wes','bak_sou','bak_nor','vic_sou','vic_nor','train'],axis=1))\n",
    "Y = np.array(final.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = make_pipeline(StandardScaler(),SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "clf3.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = new.drop(['train'],axis=1)\n",
    "labels_svm3 = clf3.predict(X_test[8616:9334])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_svm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.5))\n",
    "train_audio = moving_average(abs(return_octave_filtered(data13,samplerate=3200,octave_band=125)),1500)\n",
    "t = np.linspace(0,3600,len(train_audio))\n",
    "plt.xlabel('Time ($s$)')\n",
    "plt.ylabel('Amplitude ($V$)')\n",
    "plt.xlim([0,600])\n",
    "plt.ylim([0,0.0015])\n",
    "plt.plot(t,train_audio,color='#0098D4',lw=0.3)\n",
    "\"\"\"for i in times:\n",
    "    for j in times[i]:\n",
    "        plt.axvline(j,color='#E32017',lw=2.5,alpha=1)\n",
    "plt.axvline(times['cen_eas'][0],color='#E32017',lw=2.5,alpha=1,label='Expected Train')\"\"\"\n",
    "plt.fill_between(np.linspace(0,3600,3590),[0.0015*i for i in expand_singles(labels_svm3)], color='#E32017',alpha=0.4)\n",
    "plt.fill_between([1000,2000],[0,0],color='#E32017',alpha=0.4, label='Predicted Train')\n",
    "plt.legend(loc='upper right')\n",
    "#plt.savefig('final_figures/initial/glm_predict',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_confusion(pred, act):\n",
    "    tru_pos = 0\n",
    "    tru_neg = 0\n",
    "    fal_pos = 0\n",
    "    fal_neg = 0\n",
    "    for i,j in zip(pred,act):\n",
    "        if i==j:\n",
    "            if i==1:\n",
    "                tru_pos+=1\n",
    "            else:\n",
    "                tru_neg+=1\n",
    "        else:\n",
    "            if i==1:\n",
    "                fal_pos+=1\n",
    "            else:\n",
    "                fal_neg+=1\n",
    "    return [tru_pos,tru_neg,fal_pos,fal_neg]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_metrics(c):\n",
    "    acc = (c[0]+c[1])/(sum(c))\n",
    "    pre = c[0]/(c[0]+c[2])\n",
    "    rec = c[0]/(c[0]+c[3])\n",
    "    f1 = 2*pre*rec/(pre+rec)\n",
    "    return [acc,pre,rec,f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = make_pipeline(StandardScaler(),SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "clf3.fit(X[:2532],Y[:2532])\n",
    "labels_svm3 = clf3.predict(X[2532:2743])\n",
    "conf=find_confusion(labels_svm3, Y[2532:2743])\n",
    "print(find_metrics(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
